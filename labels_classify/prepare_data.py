import pandas as pd
from datasets import Dataset
import pickle
import os
import numpy as np

# 1. åŠ è½½å­—å…¸
DICT_PATH = '../cgm_ckp/token2id.pkl'
if not os.path.exists(DICT_PATH):
    raise FileNotFoundError(f"æ‰¾ä¸åˆ°å­—å…¸æ–‡ä»¶: {DICT_PATH}")

with open(DICT_PATH, 'rb') as f:
    token2id = pickle.load(f)


# --- ğŸ” è‡ªåŠ¨ä¾¦æµ‹ç‰¹æ®Š Token çš„ Key ---
# æœ‰äº›å­—å…¸ç”¨ <UNK>, æœ‰äº›ç”¨ <unk>, æœ‰äº›ç”¨ [UNK]
def find_key(token_dict, candidates):
    for key in candidates:
        if key in token_dict:
            return key
    return None


UNK_KEY = find_key(token2id, ['<unk>', '<UNK>', '[UNK]'])
CLS_KEY = find_key(token2id, ['<cls>', '<CLS>', '[CLS]'])
PAD_KEY = find_key(token2id, ['<pad>', '<PAD>', '[PAD]'])

# è·å–å¯¹åº”çš„ IDï¼Œå¦‚æœæ‰¾ä¸åˆ°ç‰¹æ®Šçš„ keyï¼Œå°±é»˜è®¤ç”¨ 0 æˆ– 1
unk_id = token2id[UNK_KEY] if UNK_KEY else 0
cls_id = token2id[CLS_KEY] if CLS_KEY else 0
pad_id = token2id[PAD_KEY] if PAD_KEY else 0

print(f"ğŸ“– å­—å…¸æ£€æŸ¥å®Œæ¯•:")
print(f"   UNK token: '{UNK_KEY}' -> ID: {unk_id}")
print(f"   CLS token: '{CLS_KEY}' -> ID: {cls_id}")
print(f"   PAD token: '{PAD_KEY}' -> ID: {pad_id}")


# ------------------------------------

def process_glucose(value):
    """å°†è¡€ç³–å€¼è½¬æ¢ä¸º Token IDï¼Œå¢åŠ é²æ£’æ€§é˜²æ­¢ NaN"""
    try:
        # å¤„ç†å¯èƒ½çš„ NaN æˆ–éæ•°å­—
        if pd.isna(value):
            return unk_id

        val_float = float(value)
        # é™åˆ¶èŒƒå›´ 40-300
        if val_float < 40: val_float = 40
        if val_float > 300: val_float = 300

        # å°è¯•è½¬ä¸ºå­—ç¬¦ä¸² Key
        # æœ‰äº›å­—å…¸çš„ key æ˜¯ '100' (str), æœ‰äº›å¯èƒ½æ˜¯ 100 (int)
        val_int = int(val_float)
        val_str = str(val_int)

        # ä¼˜å…ˆæ‰¾å­—ç¬¦ä¸² key
        if val_str in token2id:
            return token2id[val_str]
        # å…¶æ¬¡æ‰¾æ•°å­— key
        elif val_int in token2id:
            return token2id[val_int]
        else:
            return unk_id

    except Exception as e:
        # é‡åˆ°ä»»ä½•è§£æé”™è¯¯ï¼Œç»Ÿç»Ÿè¿”å› UNKï¼Œç»ä¸è¿”å› None
        return unk_id


# 2. è¯»å–åŸå§‹æ•°æ®
CSV_PATH = "my_cgm_data.csv"
if not os.path.exists(CSV_PATH):
    raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶: {CSV_PATH}ï¼Œè¯·å…ˆè¿è¡Œ generate_mock_data.py")

df = pd.read_csv(CSV_PATH)
print(f"ğŸ“Š æ­£åœ¨å¤„ç† {len(df)} æ¡æ•°æ®...")

data_list = []
for index, row in df.iterrows():
    # æå–è¡€ç³–åˆ— (å‡è®¾ id åœ¨ç¬¬0åˆ—, label åœ¨æœ€åä¸€åˆ—, ä¸­é—´æ˜¯è¡€ç³–)
    # æ ¹æ® generate_mock_data.py: cols = ["id"] + [g_0...g_287] + ["label"]
    # æ‰€ä»¥è¡€ç³–æ˜¯ä» ç¬¬1åˆ— åˆ° å€’æ•°ç¬¬2åˆ—
    glucose_values = row.iloc[1:-1].values

    # è½¬åŒ–ä¸º Token ID
    input_ids = [process_glucose(v) for v in glucose_values]

    # å¤´éƒ¨æ·»åŠ  CLS
    input_ids = [cls_id] + input_ids

    # ç¡®ä¿æ²¡æœ‰ None/NaN æ··è¿›å»
    # double check: å¦‚æœæœ‰ä»»ä½•éæ•´æ•°ï¼Œå¼ºè¡Œè½¬ä¸º 0
    input_ids = [int(x) if x is not None and not pd.isna(x) else unk_id for x in input_ids]

    # æ„é€ æ ·æœ¬
    data_list.append({
        "input_ids": input_ids,
        "label": int(row['label'])
    })

# 3. åˆ›å»ºå¹¶ä¿å­˜ Dataset
dataset = Dataset.from_list(data_list)
# ä¿å­˜åˆ°æ–‡ä»¶å¤¹
OUTPUT_PATH = "../labels_classify/my_processed_input"
dataset.save_to_disk(OUTPUT_PATH)
print(f"âœ… æ•°æ®ä¿®å¤å®Œæˆï¼å·²ä¿å­˜è‡³ {OUTPUT_PATH}")
print(f"   æ ·æœ¬é•¿åº¦ç¤ºä¾‹: {len(data_list[0]['input_ids'])} (åº”ä¸º 289)")